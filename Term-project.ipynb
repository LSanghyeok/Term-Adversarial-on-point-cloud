{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=6\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import os.path as osp\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.nn import PointConv, radius_graph, fps, global_max_pool, XConv, fps, global_mean_pool\n",
    "from torch_geometric.transforms import RadiusGraph\n",
    "\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "#torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(num_points, name='10'):\n",
    "    path = 'ModelNet'+name\n",
    "    pre_transform = T.NormalizeScale()\n",
    "    transform = T.SamplePoints(num_points)\n",
    "\n",
    "    train_dataset = ModelNet(\n",
    "        'dataset/' + path,\n",
    "        name=name,\n",
    "        train=True,\n",
    "        transform=transform,\n",
    "        pre_transform=pre_transform)\n",
    "    test_dataset = ModelNet(\n",
    "        'dataset/' + path,\n",
    "        name=name,\n",
    "        train=False,\n",
    "        transform=transform,\n",
    "        pre_transform=pre_transform)\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def run(train_dataset, test_dataset, model, epochs, batch_size, lr,\n",
    "        lr_decay_factor, lr_decay_step_size, weight_decay):\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "    \n",
    "    best_test_acc=0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t_start = time.perf_counter()\n",
    "\n",
    "        train(model, optimizer, train_loader, device)\n",
    "        test_acc = test(model, test_loader, device)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t_end = time.perf_counter()\n",
    "    \n",
    "       \n",
    "        \n",
    "        if best_test_acc<test_acc:\n",
    "            best_test_acc=test_acc\n",
    "            torch.save(model.state_dict(), \"saves/{}_{}\".format(model._get_name(), epoch))\n",
    "        print('Epoch: {:03d}, Test: {:.4f}, Best_Test: {:.4f}, Duration: {:.2f}'.format(\n",
    "            epoch, test_acc, best_test_acc,t_end - t_start))\n",
    "        if epoch % lr_decay_step_size == 0:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_decay_factor * param_group['lr']\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    losses=0\n",
    "    total = len(train_loader)\n",
    "    interval = 100\n",
    "    total = len(train_loader)//interval\n",
    "    for i,data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        out = model(data.pos, data.batch)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        losses+=loss\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%interval==0:\n",
    "            print(\"{}/{} loss : {:.4f}\".format(int((i+1)/interval), total, losses/interval))\n",
    "            losses=0\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.pos, data.batch).max(1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    test_acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "def print_dataset(train_dataset, test_dataset):\n",
    "    num_nodes = num_edges = 0\n",
    "    for data in train_dataset:\n",
    "        data = RadiusGraph(0.2)(data)\n",
    "        num_nodes += data.num_nodes\n",
    "        num_edges += data.num_edges\n",
    "    for data in test_dataset:\n",
    "        data = RadiusGraph(0.2)(data)\n",
    "        num_nodes += data.num_nodes\n",
    "        num_edges += data.num_edges\n",
    "\n",
    "    num_graphs = len(train_dataset) + len(test_dataset)\n",
    "    print('Graphs', num_graphs)\n",
    "    print('Nodes', num_nodes / num_graphs)\n",
    "    print('Edges', (num_edges // 2) / num_graphs)\n",
    "    print('Label rate', len(train_dataset) / num_graphs)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointNet, self).__init__()\n",
    "\n",
    "        nn = Seq(Lin(3, 64), ReLU(), Lin(64, 64))\n",
    "        self.conv1 = PointConv(local_nn=nn)\n",
    "\n",
    "        nn = Seq(Lin(67, 128), ReLU(), Lin(128, 128))\n",
    "        self.conv2 = PointConv(local_nn=nn)\n",
    "\n",
    "        nn = Seq(Lin(131, 256), ReLU(), Lin(256, 256))\n",
    "        self.conv3 = PointConv(local_nn=nn)\n",
    "\n",
    "        self.lin1 = Lin(256, 256)\n",
    "        self.lin2 = Lin(256, 256)\n",
    "        self.lin3 = Lin(256, num_classes)\n",
    "\n",
    "    def forward(self, pos, batch):\n",
    "        radius = 0.2\n",
    "        edge_index = radius_graph(pos, r=radius, batch=batch)\n",
    "        x = F.relu(self.conv1(None, pos, edge_index))\n",
    "\n",
    "        idx = fps(pos, batch, ratio=0.5)\n",
    "        x, pos, batch = x[idx], pos[idx], batch[idx]\n",
    "\n",
    "        radius = 0.4\n",
    "        edge_index = radius_graph(pos, r=radius, batch=batch)\n",
    "        x = F.relu(self.conv2(x, pos, edge_index))\n",
    "\n",
    "        idx = fps(pos, batch, ratio=0.25)\n",
    "        x, pos, batch = x[idx], pos[idx], batch[idx]\n",
    "\n",
    "        radius = 1\n",
    "        edge_index = radius_graph(pos, r=radius, batch=batch)\n",
    "        x = F.relu(self.conv3(x, pos, edge_index))\n",
    "\n",
    "        x = global_max_pool(x, batch)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "class PointCNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = XConv(0, 48, dim=3, kernel_size=8, hidden_channels=32)\n",
    "        self.conv2 = XConv(\n",
    "            48, 96, dim=3, kernel_size=12, hidden_channels=64, dilation=2)\n",
    "        self.conv3 = XConv(\n",
    "            96, 192, dim=3, kernel_size=16, hidden_channels=128, dilation=2)\n",
    "        self.conv4 = XConv(\n",
    "            192, 384, dim=3, kernel_size=16, hidden_channels=256, dilation=2)\n",
    "\n",
    "        self.lin1 = Lin(384, 256)\n",
    "        self.lin2 = Lin(256, 128)\n",
    "        self.lin3 = Lin(128, num_classes)\n",
    "\n",
    "    def forward(self, pos, batch):\n",
    "        x = F.relu(self.conv1(None, pos, batch))\n",
    "\n",
    "        idx = fps(pos, batch, ratio=0.375)\n",
    "        x, pos, batch = x[idx], pos[idx], batch[idx]\n",
    "\n",
    "        x = F.relu(self.conv2(x, pos, batch))\n",
    "\n",
    "        idx = fps(pos, batch, ratio=0.334)\n",
    "        x, pos, batch = x[idx], pos[idx], batch[idx]\n",
    "\n",
    "        x = F.relu(self.conv3(x, pos, batch))\n",
    "        x = F.relu(self.conv4(x, pos, batch))\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200\n",
    "b_size=8\n",
    "lr=0.001\n",
    "lr_decay=0.5\n",
    "lr_decay_step=50\n",
    "weight_decay=0\n",
    "train_dataset, test_dataset = get_dataset(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PointNet(train_dataset.num_classes)\n",
    "run(train_dataset, test_dataset, model, epochs, b_size, lr,\n",
    "    lr_decay, lr_decay_step, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'conv1',\n",
       " 'conv2',\n",
       " 'conv3',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'lin1',\n",
       " 'lin2',\n",
       " 'lin3',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PointNet'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelNet10(3991)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
